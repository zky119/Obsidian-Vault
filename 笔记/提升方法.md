# AdaBoost
- AdaBoost（Adaptive Boosting——自适应提升），是一种集成方法，应用提升方法的思想。算法将<font  color="#f47983"  size="5">多个弱评估器的输出结合起来创建一个强评估器</font>，从而提高整体预测精度。

## 工作原理

- 在迭代过程中，调整错误分类样本的权重。
	- 如果样本预测<font color="#f47983">正确</font>，则<font color="#f47983">降低权重</font>。 
	- 如果样本预测<font color="#f47983">错误</font>，则<font color="#f47983">提高权重</font>。 
- 在更新后的权重上训练一个新的弱分类器，以专注于难以分类的样本。 
	- 越难区分的样本在训练过程中会变得越重要。
![[Pasted image 20230611150150.png]]

## 提升预测
$$\hat{y}=F_n(x)=\sum_{i=1}^n\alpha_if_i(x)$$
- $\alpha_i$：每个基本评估器的权重。 
- $n$：基本评估器的数量。
- 对于分类任务，则在最终的结果上进行sign函数的转换即可：$$\hat{y}=sign(F_n(x))=sign(\sum_{i=1}^n\alpha_if_i(x))$$

## [[AdaBoost算法步骤]]



