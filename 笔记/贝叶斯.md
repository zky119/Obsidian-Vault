# 一，[[分类朴素贝叶斯]]
$$ P(x_i | y) = \frac{N_{yi}+\alpha}{{\text N_y+n_i\alpha}} $$

- $N_{yi}$：第$i$个特征中，类别为$y$，特征值为$x_i$的样本数量。 
- $N_y$：类别为$y$的样本数量。 
- $\alpha$：平滑系数。 
- $n_i$：第$i$个特征的类别取值数量。

## 1，介绍
- 适用场景：分类朴素贝叶斯适用于处理离散型特征变量的分类问题。它广泛应用于文本分类、垃圾邮件过滤、情感分析等领域。
	- 工作原理：分类朴素贝叶斯基于朴素贝叶斯算法，采用贝叶斯定理来计算给定特征条件下的类别概率。它假设特征之间相互独立，且每个特征对于类别的影响是相互独立的。

- 优点：
	1. 计算效率高：分类朴素贝叶斯算法的计算效率较高，因为它只需要计算各个特征的条件概率和先验概率。
	2. 对于离散型特征有效：分类朴素贝叶斯适用于处理离散型特征，如文本中的词频或词袋模型。

- 缺点：
	1. 忽略特征相关性：分类朴素贝叶斯算法忽略了特征之间的相关性，假设它们相互独立。这在某些情况下可能不符合实际情况，导致分类结果不准确。
	2. 无法处理连续型特征：分类朴素贝叶斯算法无法直接处理连续型特征，需要将其离散化或转换为离散型特征。

## 2，[[分类朴素贝叶斯代码]]


# 二，[[高斯朴素贝叶斯]]
$$P(x_i | y) = \frac{1}{{\sqrt{2\pi\sigma_{y}^2}}} \exp\left(-\frac{{(x_i - \mu_{y})^2}}{{2\sigma_{y}^2}}\right) $$
- $\mu_{y}$：在类别为$y$的样本中，特征$x_i$的均值。 
- $\sigma_{y}$：在类别为$y$的样本中，特征$x_i$的标准差。

## 1，介绍
- 适用场景：高斯朴素贝叶斯适用于处理连续型特征变量的分类问题。它常用于数据集中的实数型特征，如身高、体重、温度等。
	- 工作原理：高斯朴素贝叶斯基于朴素贝叶斯算法，假设每个特征变量的概率分布服从高斯分布（正态分布）。通过计算每个类别下特征变量的均值和方差，然后利用高斯分布的概率密度函数来估计给定特征条件下的类别概率。

- 优点：
	1. 简单有效：高斯朴素贝叶斯算法具有简单、高效的特点。在处理连续型特征时，它能够有效地估计概率分布参数，并给出准确的分类结果。
	2. 处理连续型特征：相比于其他朴素贝叶斯算法，高斯朴素贝叶斯能够直接处理连续型特征变量，无需进行离散化或转换。

- 缺点：
	1. 特征独立性假设：高斯朴素贝叶斯算法同样假设特征之间相互独立。在某些情况下，特征之间的相关性可能影响分类结果。
	2. 对于特征分布不准确的情况：如果特征分布与高斯分布假设不符，高斯朴素贝叶斯的分类效果可能会下降。

## 2，[[高斯朴素贝叶斯代码]]

# 三，[[伯努利朴素贝叶斯]]
$$P(y | x) = \frac{{P(y) \cdot \prod P(x_i | y)}}{{P(x)}}$$
 $y$: 表示类别变量，例如正类和负类。
- $x_i$: 表示第 $i$ 个特征变量，它是一个二进制变量，可以取值0或1。
- $P(y)$: 表示类别 $y$ 的先验概率。
- $P(x_i | y)$: 表示在给定类别 $y$ 的情况下特征变量 $x_i$ 的条件概率。

## 1，介绍
- 适用场景：伯努利朴素贝叶斯适用于处理二值型特征变量的分类问题，其中特征变量只能取两个值（例如0和1）。
	- 工作原理：伯努利朴素贝叶斯基于朴素贝叶斯算法，假设每个特征变量都是二值的，取0或1的概率。它通过计算每个类别下特征变量取值为1的概率，并利用伯努利分布的概率质量函数来估计给定特征条件下的类别概率。

- 优点：
	1. 简单有效：伯努利朴素贝叶斯算法简单且高效。它只需要统计每个特征取值为1的概率，无需计算其他统计量，因此计算复杂度较低。
	2. 处理二值型特征：伯努利朴素贝叶斯适用于处理二值型特征变量，这种特征在许多自然语言处理和文本分类等任务中常见。

- 缺点：
	1. 特征独立性假设：与其他朴素贝叶斯算法一样，伯努利朴素贝叶斯也假设特征之间相互独立。如果特征之间存在相关性，可能会影响分类结果。
	2. 对于非二值型特征：伯努利朴素贝叶斯只适用于处理二值型特征变量，对于非二值型特征，需要进行二值化处理，可能会导致信息损失。

2，[[伯努利朴素贝叶斯代码]]


# 四，[[多项式朴素贝叶斯]]


## 1，介绍
- 适用场景：多项式朴素贝叶斯适用于处理离散型特征变量的分类问题，其中特征变量的取值可以是整数计数或表示某种频率。
	- 工作原理：多项式朴素贝叶斯基于朴素贝叶斯算法，假设特征变量的概率分布服从多项式分布。它通过计算每个类别下特征变量的概率分布，并利用多项式分布的概率质量函数来估计给定特征条件下的类别概率。

- 优点：
	1. 处理离散型特征：多项式朴素贝叶斯适用于处理离散型特征变量，这种特征在自然语言处理、文本分类和推荐系统等任务中常见。例如，文档中的词语计数或频率可以作为离散型特征。
	2. 快速训练和预测：多项式朴素贝叶斯算法具有高效的训练和预测速度，适用于处理大规模数据集。

- 缺点：
	1. 特征独立性假设：与其他朴素贝叶斯算法一样，多项式朴素贝叶斯假设特征之间相互独立。如果特征之间存在相关性，可能会影响分类结果。
	2. 对于连续型特征：多项式朴素贝叶斯通常不能很好地处理连续型特征变量，因为它基于离散型特征的计数或频率。

2，[[多项式朴素贝叶斯代码]]


# 五，[[互补朴素贝叶斯]]


## 1，介绍
- 适用场景：互补朴素贝叶斯适用于处理不平衡数据集，即类别之间存在明显的数量差异的情况。它也适用于具有相关特征的数据集，其中特征之间可能存在依赖关系。
	- 工作原理：互补朴素贝叶斯是基于朴素贝叶斯的一种改进算法，它通过考虑类别在特征空间中的互补部分来提高分类性能。传统的朴素贝叶斯算法假设特征之间相互独立，而互补朴素贝叶斯则对每个类别的特征分布进行建模，并使用类别之间的互补信息来调整概率计算。

- 优点：
	1. 处理不平衡数据集：互补朴素贝叶斯在处理不平衡数据集时表现良好。它通过考虑少数类别在特征空间中的互补部分，更好地处理了不平衡数据集中的分类问题。
	2. 考虑特征相关性：互补朴素贝叶斯对于具有相关特征的数据集也能够表现出较好的性能。它通过建模类别的特征分布和考虑类别之间的互补信息，更准确地进行概率计算。

- 缺点：
	1. 计算复杂度较高：与传统的朴素贝叶斯算法相比，互补朴素贝叶斯的计算复杂度较高。它需要对每个类别的特征分布进行建模，并进行互补信息的计算，导致算法的训练和预测时间增加。

2，[[互补朴素贝叶斯代码]]


问：为什么计算概率时为什么是对数形式

答：[[计算概率时为什么是对数形式]]
