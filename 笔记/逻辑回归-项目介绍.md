## 一，导入库

## 二，读取

## 三，检查数据 
- 即使没有空值，也会有其他不会被转化的项

```python
# 第一种
data.info()
# 第二种
data.isnull().sum()
```

## 四，处理空值

<font  
color="FFA488"  
size="6">发现 TotalCharges 类型为 object
</font>

- 使用pd.to_numeric(errors='coerce')来转化类型不正确的列，并用nan填充不能被转化的值

```python
# 将参数转换成数值类型。
# errors="coerce" 如果遇到不能转换的数值，将值设置为NaN。
r = pd.to_numeric(data['TotalCharges'],errors='coerce')
# 输出所有问题数据。
r = data['TotalCharges'][r.isnull()]
```

- 计算[TotalCharges] 和 [MonthlyCharges] 有 0.999的关系

```python
condition = data['TotalCharges'] != ' '
total = data['TotalCharges'][condition].astype(np.float64)
month = data["MonthlyCharges"][condition]
total.corr(month * data["tenure"])
```

- 可以用 [MonthlyCharges]  *  [tenure] 得出  [TotalCharges] 

```python
# 使用如下规则来填充：

# TotalCharges = MonthlyCharges * tenure

condition = data["TotalCharges"] == " "

data.loc[condition, "TotalCharges"] = data["MonthlyCharges"][condition] * data["tenure"][condition]
data["TotalCharges"] = data["TotalCharges"].astype(np.float64)
data["TotalCharges"].value_counts()

```
## 五，检查重复值

```python
data.duplicated().sum()
```

## 六，探索性数据分析  

### 1，目标变量
- 目标变量Churn（是否流失）是类别类型，首先查看该变量的各取值分布情况。
- <font  
color="FFA488"  
size="6">DataFrame 可以直接plot</font>
 ```python
v = data["Churn"].value_counts()
a = v.plot(kind="bar")
# 图像上绘制数值。
for container in a.containers:
    a.bar_label(container)
```
![[Pasted image 20230522212416.png]]

### 2，相关性分析（<font  color="FFA488"  size="5">连续变量-类别变量</font>）
	[[sns箱型图中位数相关分析函数]]
- tenure 
```python
con2cat_analysis(data, "tenure")
# KruskalResult(statistic=948.7996915155916, pvalue=2.4191401818659714e-208)
```

- MonthlyCharges
```python
con2cat_analysis(data, "MonthlyCharges")
# KruskalResult(statistic=240.34263218324136, pvalue=3.3112855487838454e-54)
```

- TotalCharges
```python
con2cat_analysis(data, "TotalCharges")
# KruskalResult(statistic=372.37688359118584, pvalue=5.684303924636669e-83)
```

### 3，相关性分析（<font  color="FFA488"  size="5">类别变量-类别变量</font>）

- [[交叉统计数量]]
```python
# 按index与columns指定的列，交叉统计数量。

v = pd.crosstab(index=data["gender"], columns=data["Churn"])

display(v)

# normalize：规范化。index值按行规范化。按百分比统计数据，每行之和为1。

v = pd.crosstab(index=data["gender"], columns=data["Churn"], normalize="index")

display(v)
```

 - [[对两个类别变量的相关性进行分析（类别-类别）]]
	 - 画图
	 - 求[[卡方]]P值
		 - 用于确定两个分类变量之间是否存在关联性的统计方法
### 4，相关特征分析卡方P值
![[Pasted image 20230523105439.png]]
- 我们发现，在该变量中，值为“No phone service”的数量，与PhoneService变量中的“No phone service”的数量是相同的，这些信息会造成一定的<font  color="FFA488"  size="6">重复</font>。我们应该判断的，是除去“No phone service”之外，其余的类别在用户流失上是否显著。

## 七，结论
- 用户是否流失，与用户性别，是否使用电话服务没有关系。
	-  特征工程时，可以删除这两个变量。 
- 服务使用时间短，流失率较高。 
- 客户月支付费用高，流失率较高。  
- 客户累计支付总费用少，流失率较高。 
	- 这与服务时间短密切相关。 
- 老年人群流失率较高。 
- 单身，无家属人群，流失率较高。 
- 使用多线电话服务，流失率稍高，但不太显著。
-  使用互联网服务，流失率较高，尤其是使用光纤的客户，流失率很高。 
- 使用互联网服务的客户中： 
	- 不使用在线安全服务的客户，流失率很高。 
	- 不使用在线备份服务的客户，流失率很高。 
	- 不使用设备保护的客户，流失率较高。 
	- 不使用技术支持的客户，流失率较高。 
- 是否使用流媒体电视（电影）服务，流失率相差不多。 
- 月付合同客户流失率最高，两年付流失率最低。 
- 使用无纸化账单的客户，流失率较高。 
- 使用电子支票支付的客户，流失率较高。

## 八，特征工程与建模

### 1，删除无用的特征
```python
data.drop(["customerID", "gender", "PhoneService"], axis=1, inplace=True)
```

### 2，目标值处理
- sklearn要求目标值 为数值类型，即使分类任务也是如此。[[map]]
```python
data["Churn"] = data["Churn"].map({"No": 0, "Yes": 1})
```

### 3，将连续变量进行[[数据标准化]]处理
- <font  color="FFA488"  size="5">连续变量数值很大，相对于类别变量1/0会使梯度下降的w权重更新得相对很悬殊，会造成性能的浪费。 </font>
- <font  color="#A7BBEA"  size="5">只对训练集进行FIT </font>：<font  color="FFA488"  size="5">如果对整个数据集（训练集和测试集）进行FIT，就会造成数据的泄露，因为公式是 x减去平均值再除以标准差，算上测试集的数据来进行训练 会造成数据泄露，所以只用训练集的数据进行FIT</font>
```python
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)

ss = StandardScaler()

col = ["tenure", "MonthlyCharges", "TotalCharges"]
X_train_scale = ss.fit_transform(X_train[col])
X_test_scale = ss.transform(X_test[col])
```

### 4，[[交叉验证]]

### 5，类别变量处理
- [[序数编码]]
- [[One-Hot编码]]
- [[序数编码和One-Hot编码区别]]

## 九，[[超参数调整]]
- `GridSearchCV`网格搜索交叉验证类，用于自动搜索最合适的超参数组合
	- 候选参数组合。类型可以是：
		-  <font  color="FFA488"  size="6">列表类型</font>：列表中的元素为字典类型，每个字典的key与value
		-  字典类型，此时相当于是第一种情况下，列表中只有一个元素。

十，模型评估

### 1，绘制[[混淆矩阵]]，观察对角情况

### 2，通过 `from sklearn.metrics import classification_report` [[评估指标]]输出 精准率/召回率/F1

### 3，绘制[[ROC曲线]]

### 4，绘制[[PR曲线]]

### 5，选择[[最佳阈值]]
- 通过`precision_recall_curve`计算的精准率/召回率会自动加 1/0，所以元素会多一个

