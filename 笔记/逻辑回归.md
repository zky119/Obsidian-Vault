一，[[逻辑回归定义]]
 $$
 z = w_0 + w_1X_1 + w_2X_2 + \ldots + w_nX_{n  \\}  = \vec{w}^T \cdot \vec{x}
 $$
 假设真实类别的值为1与0，则模型的预测结果可以表示为：

$$
\hat{y} = 
\begin{cases}
1, & \text{z > 0} \\
0, & \text{z <= 0}
\end{cases}
$$
二，[[sigmoid函数]]
$$\sigma(x) = \frac{1}{1 + e^{-x}}$$
![[Pasted image 20230517212403.png]]

- 横轴为 z 

### 也可以这样理解
$$
\hat{y} = 
\begin{cases}
1, & {\sigma(z) > 0.5} \\
0, & {\sigma(z) <= 0.5}
\end{cases}
$$

三，[[推导过程]]

四，[[实际案例]]

五，结果可视化

六，[[计算概率值]]

七，[[绘制决策边界]]

八，混淆矩阵

1，one versus rest （OVR）
- 是A，不是A  → ↓
	- 是B，不是B → ↓
		- 是C，不是C

2，[[multinomial]]

九，模型评估

1，[[混淆矩阵]]
|    |     |    |  预测值     |
| :--- | :---: |:---: |:---: |---: |
|           |         |    负例     | 正例|
| **实际值**   |    负例    |    真负例TN     | 假正例FP|
|         |   正例     |    假负例FN    | 真正例TP|

2，[[评估指标]]


- [[正确率（Accuracy）]]表示分类器正确分类的样本数量占总样本数量的比例。
	- 用于样本分布均衡
	- 计算公式如下：

 $$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$

 

- [[精确率（Precision）]]是衡量分类模型在预测为正例的样本中，真正例的比例。计算公式如下：

  $$ Precision = \frac{TP}{TP + FP} $$

  精确率关注的是模型预测为正例的准确性。

- [[召回率（Recall）]]是衡量分类模型在所有真实正例中，预测为正例的比例。计算公式如下：

$$Recall = \frac{TP}{TP + FN} $$

  召回率关注的是模型对正例的查全率。

- [[调和平均值 F1（F1-score）]]综合考虑了精确率和召回率，是综合评价分类模型性能的指标。F1值是精确率和召回率的调和平均值，计算公式如下：

  $$F1 = \frac{2 \cdot Precision \cdot Recall}{Precision + Recall} $$

  F1值的取值范围为0到1，值越高表示模型的性能越好，综合考虑了模型的准确性和查全率。

十，ROC与AUC

1，[[ROC曲线]]
$$ FPR = \frac{FP}{FP + TN} $$
$$TPR = \frac{TP}{TP + FN} $$
2，AUC
- AUC（Area Under the Curve）是指ROC曲线下的面积，在比较多个分类模型效果时，会比ROC曲线非常直观。

3，[[ROC曲线绘制]]
```python
from sklearn.metrics import RocCurveDisplay

display = RocCurveDisplay.from_estimator(lr, X_test, y_test)
display.line_.set_marker("o")
```

十一，[[PR曲线]]

- 精准率与召回率无法同时增大，一个增大时，另外一个可能就会降低。
	- 可能降低，不表示一定会降低。
	- 也可能保持不变。
- 随着召回率的增加，精准率一定会呈现下降的趋势。
- 当对精准率或召回率具有定量要求时，P-R曲线就会非常有用。
1，[[曲线绘制]]

十二，应用场景

- 混淆矩阵：提供分类模型性能的详细视图，需要直观识别特定类型的错误。
- 正确率：样本分布均衡，且所有类别的错误分类成本大致相等。
	- 人的性别分类。
	- 颜色分类。
- 精准率：负例预测为正例（假正例）的代价很大。
	- 垃圾邮件检测。
	- 投资时机预测。
- 召回率：正例预测为负例（假负例）的代价很大。
	- 新冠阳性检测。
	- 逃犯识别。
- F1值：训练样本中类别分布不均匀或误报（假正例）和漏报（假负例）的代价不同。
	- 精准率与召回率的适用场景。
- ROC（AUC）：比较不同分类器的性能和选择最佳分类阈值。
	- 两个（或多个）模型谁的分类效果更好。

