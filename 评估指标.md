- 分别计算
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score

print("正确率：", accuracy_score(y_test, y_hat))
# 默认将类别1视为正例，可以通过pos_label参数指定。
print("精准率：", precision_score(y_test, y_hat))
print("召回率：", recall_score(y_test, y_hat))
print("F1调和平均值：", f1_score(y_test, y_hat))
# 我们也可以调用逻辑回归模型对象的score方法，也能获取正确率。
# 但是需要注意，score方法与f1_score函数的参数是不同的。
print("score方法计算正确率：", lr.score(X_test, y_test))
```

- 一块计算
```python
from sklearn.metrics import classification_report
print(classification_report(y_true=y_test, y_pred=y_hat))
```
![[Pasted image 20230523141641.png]]

- 正确率（Accuracy）是分类模型评估的一种指标，表示分类器正确分类的样本数量占总样本数量的比例。计算公式如下：

 $$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$

  其中，TP（True Positive）表示真正例的数量，即被正确地判定为正例的样本数量；TN（True Negative）表示真反例的数量，即被正确地判定为反例的样本数量；FP（False Positive）表示假正例的数量，即被错误地判定为正例的样本数量；FN（False Negative）表示假反例的数量，即被错误地判定为反例的样本数量。

- 精确率（Precision）是衡量分类模型在预测为正例的样本中，真正例的比例。计算公式如下：

  $$ Precision = \frac{TP}{TP + FP} $$

  精确率关注的是模型预测为正例的准确性。

- 召回率（Recall）是衡量分类模型在所有真实正例中，预测为正例的比例。计算公式如下：

$$Recall = \frac{TP}{TP + FN} $$

  召回率关注的是模型对正例的查全率。

- 调和平均值 F1（F1-score）综合考虑了精确率和召回率，是综合评价分类模型性能的指标。F1值是精确率和召回率的调和平均值，计算公式如下：

  $$F1 = \frac{2 \cdot Precision \cdot Recall}{Precision + Recall} $$

  F1值的取值范围为0到1，值越高表示模型的性能越好，综合考虑了模型的准确性和查全率。
