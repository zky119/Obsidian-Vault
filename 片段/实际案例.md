
```python
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split

from sklearn.datasets import load_iris

  

iris = load_iris()

X, y = iris.data, iris.target

# 因为鸢尾花具有三个类别，4个特征，此处仅使用其中两个特征，并且移除一个类别（类别0）。

X = X[y != 0, 2:]

y = y[y != 0]

# 此时，y的标签为1与2，我们这里将其改成0与1。（仅仅是为了习惯而已）

y[y == 1] = 0

y[y == 2] = 1

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)

# penalty：正则化方式。可选值为：

# l1：L1正则化。

# l2（默认值）：L2正则化。

# elasticnet：弹性网络正则化。

# None：不使用正则化，在这种情况下，会使用L2正则化，并将C值设置为无穷大。

# C：正则化强度，类似于线性回归中的alpha参数值。可以看做C为alpha的倒数，默认值为1.0。

# solver：优化求解算法。可选值为：

# liblinear：使用C++的liblinear库，支持ovr，不支持multinomial。支持L1，L2正则化。

# newton-cg：牛顿法，使用海森（Hessian）矩阵（损失函数的二阶偏导）的逆矩阵来更新权重。支持L2正则化

# 与不使用正则化。

# lbfgs（默认值）：拟牛顿法，牛顿法的一种变体，不去计算海森矩阵，而是近似去构造海森矩阵。

# 支持L2正则化与不使用正则化。

# sag：平均随机梯度下降法（Stochastic Average Gradient Descent），类似于梯度下降，只是

# 在更新权重时，考虑样本旧的梯度值。支持L2正则化与不使用正则化。

# saga：sag的一种变体（改进），理论上具有更好的收敛速度，支持所有类型正则化。

# multi_class：多分类的实现方式，可选值为：

# auto（默认值）：如果二分类，或者sover为liblinear，使用ovr，其他情况使用multinomial。

# ovr：one-versus-rest实现方式。

# multinomial：多项式实现方式。

lr = LogisticRegression()

lr.fit(X_train, y_train)

y_hat = lr.predict(X_test)

print("权重：", lr.coef_)

print("偏置：", lr.intercept_)

print("真实值：", y_test)

print("预测值：", y_hat)
```