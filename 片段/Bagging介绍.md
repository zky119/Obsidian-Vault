# 步骤
- Bagging算法采用平均方法的思想，也称为汇聚法(Bootstrap Aggregating)。
	- 在原始数据集上进行随机抽样（抽样可以是放回抽样与不放回抽样）。
	- 使用得到的随机子集来训练评估器（基本评估器）。
	- 重复步骤1与步骤2若干次，会得到n个基本评估器
	- 将n个评估器进行组合，根据多数投票（分类）或者求均值（回归）的方式来统计最终的结果（平 均方法）。
![[Pasted image 20230605172257.png]]

# 优势
- bagging方法通过随机抽样来构建原始数据集的子集，来训练不同的基本评估器，然后再将多个基本评估器进行组合来预测结果
	- 可以有效<font  color="#f47983"  size="5">减小</font>基本评估器的<font  color="#f47983"  size="5">方差</font>。
	- 可以有效的<font  color="#f47983"  size="5">降低过拟合</font>。
	- bagging方法适用于强大而复杂的模型（例如，完全生长的决策树）。
	- 可以<font  color="#f47983"  size="5">并行化处理</font>，加快训练速度。

# 劣势
- 由于每个基学习器之间是独立训练的，因此无法利用样本之间的相关性信息。
- 在处理噪声较大的数据集时可能会过拟合。
- 对于某些问题，Bagging可能无法明显改善模型性能。
