AdaBoost算法步骤如下（以<font color="#f47983">分类</font>为例）：
1. 初始化每个样本的权重 ，使得所有样本的初始权重相同，并且权重之和为1，即：$$w_1=(\frac{1}{m},\frac{1}{m},\ldots,\frac{1}{m})^T$$
2. 在第 $k$轮迭代中，使用具有权重 $w_k$的样本训练基本评估器$f_k(x)$ 。
3. 使用基本学习器$f_k(x)$ 预测样本输出值$\hat{y}$ 。
4. 计算含有权重的错误率：$$\epsilon_k=w_k\cdot\left(y\neq\hat{y}\right)$$
5. 计算第$k$ 轮的基本评估器 $f_k(x)$的权重系数$$\alpha_k=0.5*log\frac{1-\epsilon_k}{\epsilon_k}$$
6. 更新样本权重：$$w_k=w_k*e^{-\alpha_k*y*\hat{y}}$$对于预测正确的样本，降低样本权重值，否则提升样本权重值。
7. 对权重$w_k$ 进行归一化，使其和为1：$$w_k = \frac{w_j}{\sum_i w_i}$$对于更新后的 $w_k$，就会成为下一轮（第$k+1$ 轮）迭代的权重$w_{k+1}$
8. 构建基本评估器的线性组合：$$F_k(x)=\sum_{i=1}^k\alpha_if_i(x)$$- 该结果为迭代到第 $k$ 轮的预测结果
9. 重复步骤2 ~ 8，共$n$次，获得最终的评估器：$$\hat{y}=sign(F_n(x))=sign(\sum_{i=1}^n\alpha_if_i(x))$$
## [[AdaBoost示例]]

# [[泰勒公式]]

$$f(x)=\sum_{n=0}^{\infty}\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n$$
- ${f^{(n)}(x_0)}$函数 $f(x)$ 在 $x=x_0$ 处的 $n$ 阶导数。
- 当函数 $f(x)$ 在点 $x_0$ 处可导时，我们可以将函数 $f(x)$ 使用一阶泰勒在点 $x_0$ 展开：$$f(x)\approx f(x_0)+f'(x_0)(x-x_0)$$
- 二阶泰勒在点 $x_0$ 展开：$$f(x)\approx f(x_0)+f'(x_0)(x-x_0)+0.5*f''(x_0)(x-x_0)^2$$
## [[泰勒展开式示例]]
